{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e758d666-b097-4b49-a495-7cbfb18b2ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "from skmap.catalog import s3_setup, DataCatalog\n",
    "from skmap.loader import TiledDataLoader\n",
    "from skmap.overlay import SpaceOverlay, SpaceTimeOverlay\n",
    "from skmap.misc import find_files, GoogleSheet, ttprint\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import skmap_bindings as sb\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from geopandas import gpd \n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "# warnings.filterwarnings('default')\n",
    "\n",
    "folder_path = '/home/xuemeng/work_xuemeng/soc/SoilHealthDataCube/data'\n",
    "df = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504c72c-98ec-4cfe-8a65-695fe8f36f48",
   "metadata": {},
   "source": [
    "# Split train, test and calibration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a31f50-ded5-4bde-a10d-223286453a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21367/858334596.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_lc_df['stratify_col'] = (\n",
      "/tmp/ipykernel_21367/858334596.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_lc_df['stratify_col'] = other_lc_df['stratify_col'].replace(underrepresented_classes, 'merged_class')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame size: 45616\n",
      "Test DataFrame size: 2283\n",
      "Train DataFrame size: 38348\n",
      "Calibration DataFrame size: 4985\n",
      "Data successfully split into test, calibration, and training sets.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Bin `hzn_dep`\n",
    "bins = [0, 20, 50, 100, 200]\n",
    "labels = ['0-20', '20-50', '50-100', '100-200']\n",
    "df['hzn_dep_bin'] = pd.cut(df['hzn_dep'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Step 2: Pre-isolate \"water areas & wetland\"\n",
    "water_wetland_df = df[df['lc_survey'] == 'water areas & wetland']\n",
    "other_lc_df = df[df['lc_survey'] != 'water areas & wetland']\n",
    "\n",
    "# Step 3: Create stratification column for other land covers\n",
    "other_lc_df['stratify_col'] = (\n",
    "    other_lc_df['time'].astype(str) + \"_\" +\n",
    "    other_lc_df['hzn_dep_bin'].astype(str) + \"_\" +\n",
    "    other_lc_df['lc_survey'].astype(str)\n",
    ")\n",
    "\n",
    "# Step 4: Merge classes with too few samples for other land covers\n",
    "class_counts = other_lc_df['stratify_col'].value_counts()\n",
    "underrepresented_classes = class_counts[class_counts < 3].index\n",
    "other_lc_df['stratify_col'] = other_lc_df['stratify_col'].replace(underrepresented_classes, 'merged_class')\n",
    "\n",
    "# Step 5: Split other land covers\n",
    "rest_other_lc, test_other_lc = train_test_split(\n",
    "    other_lc_df,\n",
    "    test_size=0.05,\n",
    "    stratify=other_lc_df['stratify_col'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 6: Split \"water areas & wetland\" separately\n",
    "rest_water_wetland, test_water_wetland = train_test_split(\n",
    "    water_wetland_df,\n",
    "    test_size=0.2,  # Adjust as needed (e.g., 1:2 split between test and rest)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Combine test and rest datasets\n",
    "test_df = pd.concat([test_other_lc, test_water_wetland]).reset_index(drop=True)\n",
    "\n",
    "# step 8: split the rest into train and calibration\n",
    "train_other_lc, cal_other_lc = train_test_split(\n",
    "    rest_other_lc,\n",
    "    test_size=0.115,  # calibration: train = 15:80\n",
    "    stratify=rest_other_lc['stratify_col'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 9: Split \"water areas & wetland\" separately for train & cal\n",
    "train_water_wetland, cal_water_wetland = train_test_split(\n",
    "    rest_water_wetland,\n",
    "    test_size=0.4, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 10: Combine train and cal datasets\n",
    "train_df = pd.concat([train_other_lc, train_water_wetland]).reset_index(drop=True)\n",
    "cal_df = pd.concat([cal_other_lc, cal_water_wetland]).reset_index(drop=True)\n",
    "\n",
    "# Step 11: Print dataset sizes and validate\n",
    "print(f\"Original DataFrame size: {len(df)}\")\n",
    "print(f\"Test DataFrame size: {len(test_df)}\")\n",
    "print(f\"Train DataFrame size: {len(train_df)}\")\n",
    "print(f\"Calibration DataFrame size: {len(cal_df)}\")\n",
    "\n",
    "\n",
    "# Drop `stratify_col` from test data\n",
    "test_df = test_df.drop(columns=['stratify_col'])\n",
    "cal_df = cal_df.drop(columns=['stratify_col'])\n",
    "train_df = train_df.drop(columns=['stratify_col'])\n",
    "\n",
    "test_df.to_parquet(f'{folder_path}/004_data_test.pq')\n",
    "cal_df.to_parquet(f'{folder_path}/005_data_cal.pq')\n",
    "train_df.to_parquet(f'{folder_path}/006_data_train.pq')\n",
    "\n",
    "print(\"Data successfully split into test, calibration, and training sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b5a007-25f1-405b-b25c-078d669a24a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 8 4\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df['time'].unique()),len(test_df['lc_survey'].unique()), len(test_df['hzn_dep_bin'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d602bf-71c9-4726-9a3a-91672218d5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 8 4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df['time'].unique()),len(train_df['lc_survey'].unique()), len(train_df['hzn_dep_bin'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63a032c-697a-44d6-95cd-649e6b281b58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 8 4\n"
     ]
    }
   ],
   "source": [
    "print(len(cal_df['time'].unique()),len(cal_df['lc_survey'].unique()), len(cal_df['hzn_dep_bin'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd3cf86-b3c8-41f3-8af0-b31d6170f0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 8 4\n"
     ]
    }
   ],
   "source": [
    "print(len(df['time'].unique()),len(df['lc_survey'].unique()), len(df['hzn_dep_bin'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8bda21-8e3e-4e6c-be44-e57d86c839d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050048228691687124"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123c5532-eecd-4343-8ca0-0d22d63d07c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406699403717993"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e208165-1a50-4a7b-86e2-90d1fdd6a98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1092818309365135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cal_df)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06757cc-a375-4ea4-8a5f-da9f0505bb95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
