{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c493bbd7-6a00-49b7-8557-38901687b55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "from skmap.catalog import s3_setup, DataCatalog\n",
    "from skmap.loader import TiledDataLoader\n",
    "from skmap.overlay import SpaceOverlay, SpaceTimeOverlay\n",
    "from skmap.misc import find_files, GoogleSheet, ttprint\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import skmap_bindings as sb\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56ee2b-daef-45d1-9310-f67a7c41dc95",
   "metadata": {},
   "source": [
    "# Check the overlaid data, do some fix\n",
    "- drop nan values\n",
    "- assign block IDs to rows, for spatial validation\n",
    "- mend the land cover survey data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaddca3-706a-40d2-b0ee-e298f2bc3644",
   "metadata": {},
   "source": [
    "### Drop nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee1225f-63b3-4c2e-8589-fcb0814b16dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = '/home/xuemeng/work_xuemeng/soc/SoilHealthDataCube/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbf9596-28b0-423a-b078-142146f8f27e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocd data with size,  (47304, 9)\n",
      "once overlaid, size:  (47286, 598)\n"
     ]
    }
   ],
   "source": [
    "df_ocd = pd.read_parquet(f'{folder_path}/000_data_ocd.pq')\n",
    "df_old = pd.read_parquet(f'{folder_path}/001_data_overlayed.1213.pq')\n",
    "\n",
    "print('ocd data with size, ', df_ocd.shape)\n",
    "print('once overlaid, size: ', df_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65acbc68-58e6-4618-bdef-9d45495be161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5560 accum.ndvi_glad.landsat.seasconv.m.yearly_p50_30m_s_YYYY0101_YYYY1231_eu_epsg.3035_v20240513 0.12\n",
      "11268 lgd_chelsa_m_1km_s_19810101_20101231_eu_epsg.3035_v20240531 0.24\n",
      "11268 fgd_chelsa_m_1km_s_19810101_20101231_eu_epsg.3035_v20240531 0.24\n",
      "19668 fcf_chelsa_m_1km_s_19810101_20101231_eu_epsg.3035_v20240531 0.42\n",
      "\n",
      "data size after excluding invalid covs:  (47286, 594)\n",
      "data size after excluding invalid values:  (46843, 594)\n"
     ]
    }
   ],
   "source": [
    "meta = ['time', 'lat', 'lon', 'hzn_dep', 'id', 'ref', 'nuts0', 'lc_survey','ocd']\n",
    "\n",
    "# fix issue for crop layer\n",
    "# all valid values mean that the pixel is cropland\n",
    "# if a pixel is not cropland, the pixel value is nan\n",
    "crop_layer = 'cropland.extent_glad.interpolate_p_30m_s_YYYY0101_YYYY1231_eu_epsg.3035_v20240604'\n",
    "df_old.loc[df_old[crop_layer]>0,crop_layer ] = 100\n",
    "df_old.loc[df_old[crop_layer]!=100,crop_layer] = 0\n",
    "\n",
    "drop_cols = []\n",
    "df_cols = df_old.columns.values.tolist()\n",
    "var_cols = [col for col in df_cols if col not in meta]\n",
    "# check invalid values for each covariate\n",
    "for icol in df_old.columns:\n",
    "    if icol in meta:\n",
    "        continue\n",
    "    # else:\n",
    "    #     print(icol, df[icol].min(), df[icol].max())\n",
    "    elif df_old[icol].isna().sum()/len(df_old)>0.005:\n",
    "        rto = round(df_old[icol].isna().sum()/len(df_old),2)\n",
    "        print(df_old[icol].isna().sum(), icol, rto)\n",
    "        drop_cols.append(icol)\n",
    "        \n",
    "\n",
    "# for covariate with more than 0.5% invalid values, drop the covariate\n",
    "df_old = df_old.drop(columns=drop_cols)\n",
    "print('\\ndata size after excluding invalid covs: ', df_old.shape)\n",
    "# for covariate with less invalid values, drop the rows without complete valid covariate set\n",
    "var_cols = [col for col in var_cols if col not in drop_cols]\n",
    "df_old = df_old.dropna(subset = var_cols, how='any')\n",
    "print('data size after excluding invalid values: ', df_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd46aef8-5b42-4594-bda5-2874c952f1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_old.to_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9bf3b-4533-45c2-af06-3860bd8721b4",
   "metadata": {},
   "source": [
    "### assign block ID to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e6c671-96dd-445d-b651-152b462192a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  (46843, 595)\n"
     ]
    }
   ],
   "source": [
    "tiles = gpd.read_file(f'{folder_path}/002_eu.tiles_epsg.3035.gpkg')\n",
    "tiles = tiles.rename(columns={'id':'tile_id'})\n",
    "\n",
    "# dff = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')\n",
    "gdf = gpd.GeoDataFrame(df_old, geometry=gpd.points_from_xy(df_old.lon, df_old.lat))\n",
    "gdf.crs = 'EPSG:4326'\n",
    "gdf = gdf.to_crs(tiles.crs)\n",
    "\n",
    "# join spatial\n",
    "joined_gdf = gpd.sjoin(gdf, tiles, how=\"left\", op='within')\n",
    "joined_gdf = joined_gdf.drop(columns=['geometry','index_right'])\n",
    "\n",
    "print(f'data size: ', joined_gdf.shape)\n",
    "\n",
    "joined_gdf.to_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c51ba2-c91e-4062-b02e-007bcf47d396",
   "metadata": {
    "tags": []
   },
   "source": [
    "### mend the land cover data from original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b42d99d-e0c7-4c92-93e8-c9c55254c864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  (46843, 595)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')\n",
    "print('data size: ', df.shape)\n",
    "\n",
    "glc = 'lc_glc.fcs30d_c_30m_s_YYYY0101_YYYY1231_go_epsg.4326_v20231026'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59bb7c46-58f3-4160-8025-8c757428e145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46843, 595) (46843, 595)\n"
     ]
    }
   ],
   "source": [
    "de = pd.read_parquet('/home/xuemeng/work_xuemeng/ai4sh_data.harmo/data_v2/germany_harmonized_l1.pq')\n",
    "es1 = pd.read_parquet('/home/xuemeng/work_xuemeng/ai4sh_data.harmo/data_v2/spain.ParcelasCOS_harmonized_l1.pq')\n",
    "es2 = pd.read_parquet('/home/xuemeng/work_xuemeng/ai4sh_data.harmo/data_v2/spain.ParcelasINES_harmonized_l1.pq')\n",
    "pt = pd.read_parquet('/home/xuemeng/work_xuemeng/ai4sh_data.harmo/data_v2/portugal_harmonized_l1.pq')\n",
    "\n",
    "md = pd.concat([de,es1,es2,pt])\n",
    "\n",
    "md['hzn_dep'] = (md['hzn_top']+md['hzn_btm'])/2\n",
    "\n",
    "meta = ['lat', 'lon', 'time', 'hzn_dep', 'ref', 'nuts0', 'id']\n",
    "num_cols = ['lat', 'lon', 'time', 'hzn_top', 'hzn_btm']\n",
    "for col in num_cols:\n",
    "    md[col] = pd.to_numeric(md[col], errors='coerce')    \n",
    "    \n",
    "str_cols = ['id','ref','nuts0']\n",
    "for col in str_cols:\n",
    "    md[col] = md[col].astype(str)\n",
    "    \n",
    "md = md.drop_duplicates(subset=meta)\n",
    "\n",
    "merged = df.merge(md[meta + ['lc_survey']], on=meta, how='left', suffixes=('', '_fill'))\n",
    "merged['lc_survey'] = merged['lc_survey'].combine_first(merged['lc_survey_fill'])\n",
    "merged.drop(columns=['lc_survey_fill'], inplace=True)\n",
    "\n",
    "print(merged.shape, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af11ea7-9b67-4f76-9db4-4bc5c6ba95eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# harmmonize code to match lucas code level 1\n",
    "# LUCAS\n",
    "lucas_values = [\n",
    "    'B13', 'C10', 'B16', 'C23', 'C21', 'B11',\n",
    "    'E20', 'C31', 'B12', 'B82', 'E10', 'A30', 'B41', 'B22', 'B31',\n",
    "    'B33', 'C33', 'B18', 'E30', 'C32', 'B21', 'B55', 'B32', 'B15',\n",
    "    'D10', 'B84', 'B52', 'B17', 'B53', 'C22', 'B37', 'B36', 'B74',\n",
    "    'B81', 'B54', 'D20', 'B75', 'F40', 'B19', 'B35', 'B14', 'B51',\n",
    "    'B71', 'H12', 'B23', 'B43', 'B34', 'G21', 'B42', 'B73', 'B72',\n",
    "    'B76', 'B77', 'A22', 'B45', 'B83', 'H11', 'B44', 'F10', 'F30',\n",
    "    'F20'\n",
    "]\n",
    "lucas_level1 = [code[0]+'00' for code in lucas_values]\n",
    "lucas_code = dict(zip(lucas_values,lucas_level1))\n",
    "\n",
    "# spain\n",
    "# spain_code = {'CL':'B00', 'GL':'E00', 'FL':'C00'} #, 'OL':'others'\n",
    "\n",
    "# # germany\n",
    "# de_code = {'A':'B00', 'G':'E00', 'SO':'B00'}\n",
    "\n",
    "# # glance \n",
    "# glance_code = {'Rock':'F00', 'Beach/sand':'F00'}\n",
    "\n",
    "# # portugal\n",
    "# pt_code = {'Rainfed arable crop': 'B00',\n",
    "#            'Mixed crops': 'B00',\n",
    "#            'Fallow':'B00',\n",
    "#            'Pine forest': 'C00',\n",
    "#            'Horticulture':'B00',\n",
    "#            'Forest': 'C00',\n",
    "#            'Mediterranean woodland': 'C00',\n",
    "#            'Pasture': 'E00',\n",
    "#            'Quercus forest': 'C00',\n",
    "#            'Vineyard': 'B00',\n",
    "#            'Irrigated arable crop': 'B00',\n",
    "#            'Olive grove':'B00',\n",
    "#            'Eucalypt forest': 'C00',\n",
    "#            'Fruit trees': 'B00',\n",
    "#            'Cedars': 'C00',\n",
    "#            'Sugar beet': 'B00',\n",
    "#            'Melon': 'B00',\n",
    "#            'Cotton': 'B00',\n",
    "#            'Golf course': 'E00'}\n",
    "\n",
    "code_dict = {**lucas_code, **spain_code, **de_code, **glance_code, **pt_code}\n",
    "\n",
    "merged['lc_survey'] = merged['lc_survey'].map(code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75beef85-a274-4ba1-a693-adfa6d652cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# then convert code to names\n",
    "survey_dict = {\n",
    "    \"A00\": \"artificial land\",\n",
    "    \"B00\": \"cropland\",\n",
    "    \"C00\": \"woodland\",\n",
    "    \"D00\": \"shrubland\",\n",
    "    \"E00\": \"grassland\",\n",
    "    \"F00\": \"bare land & lichens/moss\",\n",
    "    \"G00\": \"water areas & wetland\", # water areas\n",
    "    \"H00\": \"water areas & wetland\", #\"wetland\",\n",
    "}\n",
    "merged['lc_survey'] = merged['lc_survey'].map(survey_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c960e9-7add-4f72-a00e-3027cad09c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 rows with invalid land cover survey data\n",
      "(46843, 594)\n"
     ]
    }
   ],
   "source": [
    "merged = merged.drop(columns=[glc])\n",
    "v_num = merged['lc_survey'].isna().sum()\n",
    "print(f'{v_num} rows with invalid land cover survey data')\n",
    "print(merged.shape)\n",
    "merged.to_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9f2f5d-b103-4ad2-af33-b13d6f26e2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meged = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f38384-e2b9-4aec-b7d7-c6d3eba67fd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mend nuts0 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b493cd5-30ac-491f-92d8-4de1e07c186e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "nuts = gpd.read_file('/home/xuemeng/work_xuemeng/ai4sh_data.harmo/raw_data/EU/EU_nuts/NUTS_RG_20M_2021_3035.shp')\n",
    "nuts = nuts.loc[nuts['LEVL_CODE']==0]\n",
    "\n",
    "df = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')\n",
    "\n",
    "# dff = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "gdf.crs = 'EPSG:4326'\n",
    "gdf = gdf.to_crs(nuts.crs)\n",
    "\n",
    "# join spatial\n",
    "joined_gdf = gpd.sjoin(gdf, nuts, how=\"left\", op='within')\n",
    "joined_gdf = joined_gdf.drop(columns=['LEVL_CODE', 'CNTR_CODE', 'NAME_LATN', 'NUTS_NAME','MOUNT_TYPE', 'URBN_TYPE', 'COAST_TYPE', 'FID', 'geometry','index_right'])\n",
    "\n",
    "# fill in\n",
    "joined_gdf.loc[joined_gdf['nuts0'].isna(),'nuts0'] = joined_gdf.loc[joined_gdf['nuts0'].isna(),'NUTS_ID']\n",
    "\n",
    "# mannual mend\n",
    "joined_gdf.loc[joined_gdf['lat']==61.13332565,'nuts0'] = 'NO'  # norway\n",
    "joined_gdf.loc[(joined_gdf['nuts0'].isna()) & (joined_gdf['lat']>48),'nuts0'] = 'UA' # ukraine\n",
    "joined_gdf.loc[joined_gdf['nuts0'].isna(), 'nuts0'] = 'TR' # turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6eada5b-f85e-4d3f-bf27-0a31bdee915f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46843, 594)\n"
     ]
    }
   ],
   "source": [
    "joined_gdf = joined_gdf.drop(columns=['NUTS_ID'])\n",
    "print(joined_gdf.shape)\n",
    "joined_gdf = joined_gdf.to_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98131e72-704c-49e5-9954-f98c9f193557",
   "metadata": {},
   "source": [
    "# Organize covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6962c4bf-5cf9-4fcb-a570-0dfeabfa281a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "other_cols = ['time', 'lat', 'lon', 'id', 'ref', 'nuts0', 'lc_survey', 'ocd','tile_id']\n",
    "cov_cols= []\n",
    "for col in df.columns:\n",
    "    if col not in other_cols:\n",
    "        cov_cols.append(col)\n",
    "\n",
    "with open(f'{folder_path}/007_cov_all.json', \"w\") as file:\n",
    "    json.dump(cov_cols, file)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d08300d-7e17-46d9-af70-9df9a699508f",
   "metadata": {},
   "source": [
    "# Check data validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0bccae-b6d7-48f0-a62a-858557ea9c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac71678-a2da-4078-8825-3dd286324099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>lc_survey</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParcelasINES</td>\n",
       "      <td>cropland</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParcelasINES</td>\n",
       "      <td>grassland</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParcelasINES</td>\n",
       "      <td>woodland</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ref  lc_survey  count\n",
       "0  ParcelasINES   cropland    567\n",
       "1  ParcelasINES  grassland    337\n",
       "2  ParcelasINES   woodland    315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = df.loc[(df['ocd']==0) & (df['lc_survey']!= 'bare land & lichens/moss') & (df['hzn_dep']<30)]\n",
    "grp = m.groupby(['ref', 'lc_survey']).size().reset_index(name='count')\n",
    "grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae0de27-e3b3-4890-ada8-33bc1caa5507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size after palusibility check (45616, 594)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[~((df['ocd'] == 0) & (df['lc_survey'] != 'bare land & lichens/moss') & (df['hzn_dep']<30))]\n",
    "print('data size after palusibility check', df.shape)\n",
    "df.to_parquet(f'{folder_path}/003_data_overlaid.organized.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fed2e5-56f4-4388-a713-2a05751daeff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
