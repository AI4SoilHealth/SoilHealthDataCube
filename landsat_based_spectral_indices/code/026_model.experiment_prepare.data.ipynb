{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941017a7-a119-441b-8904-365e23d17bb6",
   "metadata": {},
   "source": [
    "### organize the training dataset for lulc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f4c01c-b610-458d-b444-0119aac3a6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dff = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/003_data_soc.txt', low_memory=False)\n",
    "# dff = dff.drop(columns=['hzn_top', 'hzn_btm', 'ref', 'nuts0', 'oc'])\n",
    "# dff = dff.add_suffix('_datacube2024')\n",
    "\n",
    "\n",
    "import joblib\n",
    "file_path = '/mnt/primus/xuemeng_tmp_harbour/tillage_index/lucas_ls_preprocessed.joblib'\n",
    "edc = joblib.load(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "edc = pd.DataFrame(edc)\n",
    "edc['time'] = edc['survey_date'].dt.year.astype(float)\n",
    "edc['point_id'] = edc['point_id'].astype(int)\n",
    "\n",
    "result = pd.merge(dff, edc, left_on=['id','time'], right_on=['point_id','time'],how='inner')\n",
    "result = result.drop(columns='tile_id_y')\n",
    "result = result.rename(columns={'tile_id_x':'tile_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c95bc03-2d77-41d3-a780-dd3e4e3a14e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## soc\n",
    "oc_meta = ['id', 'lat', 'lon', 'time', 'hzn_top', 'hzn_btm', 'ref', 'nuts0', 'oc', 'tile_id']\n",
    "with open('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/000_feature_all.txt') as f:\n",
    "    oc_all = f.read().splitlines()\n",
    "    \n",
    "oc = result[oc_meta+oc_all]\n",
    "oc.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/003_data_soc.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3163d516-9fa9-45a7-b74f-334ab4ef52f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## lc\n",
    "lc = result.drop(columns=['time', 'hzn_top', 'hzn_btm', 'ref', 'nuts0', 'oc'])\n",
    "lc.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/004_data_lc.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397dc79-926a-4bfa-9f10-6cfb268cb1fb",
   "metadata": {},
   "source": [
    "### separate training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c303e939-0ae3-4aa7-ac60-a822fa8ffe10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test = result.groupby('tile_id', group_keys=False).apply(lambda x: x.sample(n=max(1, int(np.ceil(0.1 * len(x))))))\n",
    "train = result.loc[~result.index.isin(test.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d94aae-e57d-463f-96d4-bcb57fb78b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oc_train = train[oc_meta+oc_all]\n",
    "oc_train.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/003.1_data.train_soc.txt', index=False)\n",
    "\n",
    "lc_train = train.drop(columns=['time', 'hzn_top', 'hzn_btm', 'ref', 'nuts0', 'oc'])\n",
    "lc_train.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/004.1_data.train_lc.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c3e6d01-0550-454f-ab9c-776d99652d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oc_test = test[oc_meta+oc_all]\n",
    "oc_test.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/003.2_data.test_soc.txt', index=False)\n",
    "\n",
    "lc_test = test.drop(columns=['time', 'hzn_top', 'hzn_btm', 'ref', 'nuts0', 'oc'])\n",
    "lc_test.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/004.2_data.test_lc.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15244460-8587-459a-aafc-09733001fa20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52306"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba54f6cb-3413-4a98-aca2-d0263ff81f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8417"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1430945-bbfa-44f5-8d7a-df585f5957b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60723"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff8e15-9e6b-4f21-9240-e57f153f42b8",
   "metadata": {},
   "source": [
    "### organize the training set for soc regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab481b50-6566-4367-93af-16bfa2ad80a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/soc/data/test_covar_overlayed.csv', low_memory=False)\n",
    "\n",
    "from eumap.misc import find_files, nan_percentile, GoogleSheet, ttprint\n",
    "with open('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/000_feature_all.txt') as f:\n",
    "    name = f.read().splitlines()\n",
    "\n",
    "meta = ['id', 'lat', 'lon', 'time', 'hzn_top', 'hzn_btm', 'ref', 'nuts0', 'oc', 'tile_id']\n",
    "dff = df[meta+name]\n",
    "dff = dff.loc[dff['ref']=='LUCAS']  # only LUCAS\n",
    "dff = dff.loc[(dff['hzn_btm']==20) & (dff['hzn_top']==0)] # only top soil 0-20cm\n",
    "dff = dff.dropna(subset=name+['oc']) # all valid\n",
    "\n",
    "dff.to_csv('/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/003_data_soc.txt',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550420dd-7c55-421f-bf82-3a912b7aa00c",
   "metadata": {},
   "source": [
    "### organize the feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21286c15-b3bc-4c68-9595-514bb6ad5b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# read in potential usable overlay files\n",
    "key_file = '/mnt/inca/soc_eu_model/gaia-319808-913d36b5fca4.json'\n",
    "url = 'https://docs.google.com/spreadsheets/d/1eIoPAvWM5jrhLrr25jwguAIR0YxOh3f5-CdXwpcOIz8/edit#gid=0'\n",
    "\n",
    "gsheet = GoogleSheet(key_file, url)\n",
    "covar = gsheet.covar\n",
    "covar = covar.iloc[0:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62c699b-c30e-474c-8f2a-dbf2cda0cfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to generate file paths by year, and check if the urls are valid\n",
    "def generate_overlay_path(row,year,filt=None):\n",
    "            \n",
    "    # determine if static variable\n",
    "    if row['temporal resolution'] == 'static':\n",
    "        return [row['path']],[row['path']],[row['landsat']],[row['theme']]\n",
    "    \n",
    "    if row['temporal resolution'] == 'long term':\n",
    "        perc_list = row['perc'].split(',')\n",
    "        output_paths = [row['path'].replace('{perc}', perc) for perc in perc_list]\n",
    "        return output_paths, output_paths, [row['landsat'] for i in output_paths], [row['theme'] for i in output_paths]\n",
    "        \n",
    "    # determine if the year is ahead of the availibility of the variable\n",
    "    if year>int(row['end year']):\n",
    "        year = int(row['end year'])\n",
    "    \n",
    "    # determine if it's an annual variable or (bi)monthly variable\n",
    "    if '{start_m}' not in row['path']:\n",
    "        output_paths = [row['path'].replace('{year}',f'{int(year)}')]\n",
    "    else:\n",
    "        output_paths = []\n",
    "        start_list = row['start_m'].split(', ')\n",
    "        end_list = row['end_m'].split(', ')\n",
    "        output_paths = [row['path'].replace('{year}',f'{int(year)}').replace('{start_m}',start_list[i]).replace('{end_m}',end_list[i]) for i in range(len(end_list))]\n",
    "    \n",
    "    if '{perc}' in row['path']:\n",
    "        perc_list = row['perc'].split(',')\n",
    "        output_paths = [p.replace('{perc}', perc) for p in output_paths for perc in perc_list]\n",
    "        \n",
    "    if (row['leap year'] == '1') & (year%4==0):\n",
    "        output_paths = [p.replace('0228', '0229') if '0228' in p else p for p in output_paths]\n",
    "    \n",
    "    return output_paths, [i.replace(str(int(year)),'{year}') for i in output_paths], [row['landsat'] for i in output_paths], [row['theme'] for i in output_paths]\n",
    "    \n",
    "import requests\n",
    "def check_path(url):\n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True, timeout=5)\n",
    "        # Check if the status code is not 200 (OK). You might want to specifically check for 404 or other error codes.\n",
    "        if response.status_code == 404:\n",
    "            print(f\"{url} returned HTTP 404 Not Found\")\n",
    "            return url\n",
    "        elif response.status_code != 200:\n",
    "            print(f\"{url} returned HTTP {response.status_code}\")\n",
    "            return url\n",
    "        return None  # URL is fine (HTTP 200), or you might want to handle redirections (HTTP 3xx) separately if needed.\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to retrieve {url}: {str(e)}\")\n",
    "        return url\n",
    "    \n",
    "# # check function validity\n",
    "# # generate paths\n",
    "# paths = []\n",
    "# for index,row in covar.iterrows():\n",
    "#     paths.extend(generate_overlay_path(row,2000))\n",
    "    \n",
    "pathl = []\n",
    "namel = []\n",
    "tier = []\n",
    "theme = []\n",
    "year = 2000\n",
    "for index,row in covar.iterrows():\n",
    "    if row['landsat']=='':\n",
    "        continue\n",
    "    paths, names, tiers, themes = generate_overlay_path(row, year)\n",
    "    pathl.extend(paths)\n",
    "    namel.extend(names)\n",
    "    tier.extend(tiers)\n",
    "    theme.extend(themes)\n",
    "    \n",
    "for i in pathl:\n",
    "    check_path(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ff80ff9-af32-4af4-859f-b477485f5ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atheme = list(set(theme))\n",
    "         \n",
    "for itheme in atheme:\n",
    "    setl = []\n",
    "    for jjj in range(len(name)):\n",
    "        if theme[jjj] == itheme:\n",
    "            setl.append(name[jjj])\n",
    "    \n",
    "    with open(f'/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/001_feature_theme.{itheme}.txt', 'w') as file:\n",
    "        for item in setl:\n",
    "            file.write(f\"{item}\\n\")\n",
    "            \n",
    "atier = list(set(tier))\n",
    "         \n",
    "for itier in atier:\n",
    "    setl = []\n",
    "    for jjj in range(len(name)):\n",
    "        if tier[jjj] == itier:\n",
    "            setl.append(name[jjj])\n",
    "    \n",
    "    with open(f'/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/002_feature_tier.{itier}.txt', 'w') as file:\n",
    "        for item in setl:\n",
    "            file.write(f\"{item}\\n\")\n",
    "            \n",
    "name = [i.split('/')[-1][0:-4] for i in name]\n",
    "with open(f'/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/000_feature_all.txt', 'w') as file:\n",
    "    for item in namel:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd983336-b57a-4d83-bd44-c701a40982e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'/mnt/primus/xuemeng_tmp_harbour/tillage_index/data_and_feature_set/000_feature_all.txt', 'w') as file:\n",
    "    for item in name:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249fc04-c432-4802-b7f6-f6e7f2f36cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
